{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0WK0iyc6mmBRmydzB3OMP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xjdeng/hyperliquid_testnet_trading/blob/main/hyperliquid_momentum%2Bsentiment_strat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 0: Setup"
      ],
      "metadata": {
        "id": "s_Rm_X8jgXfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ### Install hyperliquid sdk\n",
        "\n",
        "!pip install hyperliquid-python-sdk duckduckgo-search"
      ],
      "metadata": {
        "id": "hbNIfH80liwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_most_liquid = 50 # @param {\"type\":\"integer\",\"placeholder\":\"50\"}\n",
        "n_hours_lookback= 24 # @param {\"type\":\"integer\",\"placeholder\":\"24\"}\n",
        "n_picks = 10 # @param {\"type\":\"integer\",\"placeholder\":\"10\"}\n",
        "hours_holding_period = 1 # @param {\"type\":\"integer\",\"placeholder\":\"1\"}\n",
        "number_holding_periods = 999999999999 # @param {\"type\":\"integer\",\"placeholder\":\"99999999999\"}\n",
        "gemini_model = \"gemini-1.5-flash-latest\" # @param {\"type\":\"string\"}\n"
      ],
      "metadata": {
        "id": "t5gYWdMzxqPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from eth_account import Account\n",
        "from hyperliquid.exchange import Exchange\n",
        "from hyperliquid.info import Info\n",
        "from hyperliquid.utils import constants\n",
        "from google.colab import userdata\n",
        "import logging\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from duckduckgo_search import DDGS\n",
        "import enum\n",
        "import json\n",
        "from typing_extensions import TypedDict\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "assert GOOGLE_API_KEY is not None\n",
        "import google.generativeai as genai\n",
        "from decimal import Decimal, ROUND_DOWN\n",
        "from datetime import datetime, timedelta\n",
        "from math import floor\n",
        "\n",
        "\n",
        "# Reconfigure logging to ensure output appears.\n",
        "for handler in logging.root.handlers[:]:\n",
        "    logging.root.removeHandler(handler)\n",
        "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logging.debug(\"Logging is working\")\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel(gemini_model)\n",
        "\n",
        "\n",
        "private_key = userdata.get(\"hypernet_private_key\")\n",
        "account = Account.from_key(private_key)\n",
        "address = account.address\n",
        "\n",
        "exchange = Exchange(account, constants.TESTNET_API_URL)\n",
        "info = Info(constants.TESTNET_API_URL)\n",
        "# Query balance\n",
        "balance_info = info.user_state(account.address)\n",
        "print(balance_info)"
      ],
      "metadata": {
        "id": "CRpXAfHol7f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta, asset_ctxs = info.meta_and_asset_ctxs()"
      ],
      "metadata": {
        "id": "xJd-sm2K8F8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine names with their associated liquidity data\n",
        "market_stats = [\n",
        "    {\n",
        "        \"name\": m[\"name\"],\n",
        "        \"dayNtlVlm\": float(a[\"dayNtlVlm\"]),\n",
        "        \"openInterest\": float(a[\"openInterest\"]),\n",
        "        \"impactPxs\": a.get(\"impactPxs\", None)\n",
        "    }\n",
        "    for m, a in zip(meta[\"universe\"], asset_ctxs)\n",
        "]\n",
        "\n",
        "# Sort by 24h volume (descending) and take top 10\n",
        "top_markets_all = sorted(market_stats, key=lambda x: x[\"dayNtlVlm\"], reverse=True)\n",
        "top_markets = top_markets_all[:top_n_most_liquid]"
      ],
      "metadata": {
        "id": "A4ELamy1Cr6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(top_markets_all)"
      ],
      "metadata": {
        "id": "FVDLEBcEC7Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_hourly_candles(info, coin, lookback_hours=n_hours_lookback):\n",
        "    now = datetime.utcnow()\n",
        "    start = now - timedelta(hours=lookback_hours)\n",
        "    start_ts = int(start.timestamp() * 1000)\n",
        "    end_ts = int(now.timestamp() * 1000)\n",
        "\n",
        "    candles = info.candles_snapshot(\n",
        "        name=coin,\n",
        "        interval=\"1h\",\n",
        "        startTime=start_ts,\n",
        "        endTime=end_ts\n",
        "    )\n",
        "    return candles\n",
        "\n",
        "def prepare_ohlc_points(candles):\n",
        "    # Each candle has o, h, l, c\n",
        "    all_points = []\n",
        "    for candle in candles:\n",
        "        o, h, l, c = float(candle[\"o\"]), float(candle[\"h\"]), float(candle[\"l\"]), float(candle[\"c\"])\n",
        "        all_points.extend([o, h, l, c])  # 4 points per bar\n",
        "    return np.array(all_points)\n",
        "\n",
        "def compute_slope_std_ratio(y_vals):\n",
        "    x_vals = np.arange(len(y_vals))\n",
        "    A = np.vstack([x_vals, np.ones_like(x_vals)]).T\n",
        "    slope, intercept = np.linalg.lstsq(A, y_vals, rcond=None)[0]\n",
        "    y_pred = slope * x_vals + intercept\n",
        "    residuals = y_vals - y_pred\n",
        "    std_dev = np.std(residuals)\n",
        "    if std_dev == 0:\n",
        "        return float(\"-inf\")\n",
        "    return slope / std_dev"
      ],
      "metadata": {
        "id": "LVSQT1IhC9Cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Function to fetch 24 hourly candles for a given coin\n",
        "def get_hourly_candles(info, coin, lookback_hours=24):\n",
        "    now = datetime.utcnow()\n",
        "    start = now - timedelta(hours=lookback_hours)\n",
        "    start_ts = int(start.timestamp() * 1000)\n",
        "    end_ts = int(now.timestamp() * 1000)\n",
        "    # Use the candles_snapshot method to fetch data\n",
        "    candles = info.candles_snapshot(name=coin, interval=\"1h\", startTime=start_ts, endTime=end_ts)\n",
        "    return candles\n",
        "\n",
        "# Prepare OHLC points: extract open, high, low, close from each candle (4 points per candle)\n",
        "def prepare_ohlc_points(candles):\n",
        "    all_points = []\n",
        "    for candle in candles:\n",
        "        try:\n",
        "            o = float(candle[\"o\"])\n",
        "            h = float(candle[\"h\"])\n",
        "            l = float(candle[\"l\"])\n",
        "            c = float(candle[\"c\"])\n",
        "            all_points.extend([o, h, l, c])\n",
        "        except Exception as e:\n",
        "            print(\"Error processing candle:\", candle, e)\n",
        "    return np.array(all_points)\n",
        "\n",
        "# Compute regression slope and standard deviation of residuals, then return slope/std\n",
        "def compute_slope_std_ratio(y_vals):\n",
        "    x_vals = np.arange(len(y_vals))\n",
        "    A = np.vstack([x_vals, np.ones_like(x_vals)]).T\n",
        "    slope, intercept = np.linalg.lstsq(A, y_vals, rcond=None)[0]\n",
        "    y_pred = slope * x_vals + intercept\n",
        "    residuals = y_vals - y_pred\n",
        "    std_dev = np.std(residuals)\n",
        "    if std_dev == 0:\n",
        "        return float(\"-inf\")\n",
        "    return slope / std_dev\n",
        "\n",
        "# Robust wrapper to fetch candles with unlimited retries for HTTP 429 errors\n",
        "def safe_get_candles(info, coin, initial_delay=1, max_delay=60):\n",
        "    delay = initial_delay\n",
        "    attempt = 0\n",
        "    while True:\n",
        "        try:\n",
        "            candles = get_hourly_candles(info, coin)\n",
        "            return candles\n",
        "        except Exception as e:\n",
        "            # Try to extract error code from exception attributes or message\n",
        "            code = None\n",
        "            if hasattr(e, \"status_code\"):\n",
        "                code = e.status_code\n",
        "            elif isinstance(e, tuple) and len(e) > 0:\n",
        "                code = e[0]\n",
        "            elif \"429\" in str(e):\n",
        "                code = 429\n",
        "\n",
        "            if code == 429:\n",
        "                attempt += 1\n",
        "                print(f\"Rate limit hit for {coin}, retrying in {delay} seconds... (attempt {attempt})\")\n",
        "                time.sleep(delay)\n",
        "                # Exponential backoff with cap\n",
        "                delay = min(delay * 2, max_delay)\n",
        "            else:\n",
        "                raise e\n",
        "\n",
        "# Main loop: iterate over the top_markets (top 100 securities) and compute the regression-based score.\n",
        "signal_scores = []\n",
        "\n",
        "for market in top_markets:\n",
        "    name = market[\"name\"]\n",
        "    try:\n",
        "        candles = safe_get_candles(info, name)\n",
        "        if len(candles) < 24:\n",
        "            print(f\"Not enough data for {name}.\")\n",
        "            continue  # skip if insufficient data\n",
        "        points = prepare_ohlc_points(candles)  # 96 points total (24 bars * 4 OHLC points)\n",
        "        if len(points) == 0:\n",
        "            continue\n",
        "        score = compute_slope_std_ratio(points)\n",
        "        signal_scores.append({\n",
        "            \"name\": name,\n",
        "            \"score\": score\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {name}: {e}\")\n",
        "\n",
        "# Sort the watchlist by the computed score (slope / volatility ratio) in descending order\n",
        "ranked_markets = sorted(signal_scores, key=lambda x: x[\"score\"], reverse=True)\n",
        "print(\"Ranked Markets (top 10):\")\n",
        "for i, market in enumerate(ranked_markets[:10], 1):\n",
        "    print(f\"{i}. {market['name']} - Score: {market['score']:.4f}\")\n"
      ],
      "metadata": {
        "id": "3Jrif2EcFLpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_crypto_news_text(ticker, max_results=50):\n",
        "    query = f\"{ticker} crypto news\"\n",
        "    results = []\n",
        "\n",
        "    with DDGS() as ddgs:\n",
        "        for r in ddgs.news(query, max_results=max_results):\n",
        "            title = r.get(\"title\", \"\").strip()\n",
        "            body = r.get(\"body\", \"\").strip()\n",
        "            url = r.get(\"url\", \"\").strip()\n",
        "            if title:\n",
        "                results.append(f\"{title}\\n{body}\\n{url}\\n\")\n",
        "\n",
        "    return \"\\n\".join(results)"
      ],
      "metadata": {
        "id": "Cl9rPm1cLJde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Sentiment(enum.Enum):\n",
        "  negative = \"negative\"\n",
        "  neutral = \"neutral\"\n",
        "  positive = \"positive\"\n",
        "\n",
        "class Confidence(enum.Enum):\n",
        "  low = \"low\"\n",
        "  medium = \"medium\"\n",
        "  high = \"high\"\n",
        "\n",
        "class Result(TypedDict):\n",
        "    sentiment: Sentiment\n",
        "    confidence: Confidence\n",
        "    explanation: str\n",
        "\n",
        "def predict_sentiment_llm(txt, crypto):\n",
        "    prompt = f\"\"\"\n",
        "    Gauge the overall sentiment of the Duckduckgo Search Results below about a particular cryptocurrency: {crypto}.\n",
        "    If there are both positive and negative sentiment articles in the mix, pay attention to which side seems to be more dominant.\n",
        "    Weight more recent news more than older news.\n",
        "    If neither positive or negative news is clearly dominant, then the sentiment is neutral\n",
        "    Please also state your confidence in the prediction and give an explanation for the type you chose and your confidence in it.\n",
        "\n",
        "    Search Results:\n",
        "    ---\n",
        "    {txt}\n",
        "    ---\n",
        "    \"\"\"\n",
        "    result = model.generate_content(prompt,\n",
        "                                    generation_config = genai.GenerationConfig(\n",
        "                                        response_mime_type=\"application/json\", response_schema=Result\n",
        "                                    ))\n",
        "    return json.loads(result.to_dict()['candidates'][0]['content']['parts'][0]['text'])\n",
        "\n",
        "def predict_sentiment(crypto):\n",
        "  news = get_crypto_news_text(crypto)\n",
        "  #print(news[0:500])\n",
        "  return predict_sentiment_llm(news, crypto)"
      ],
      "metadata": {
        "id": "5ou6FYGKRD4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_final_picks(original_list, min_ratio = 0, n = n_picks):\n",
        "  resulting_list = []\n",
        "  for coin in original_list:\n",
        "    if coin['score'] < min_ratio:\n",
        "      continue\n",
        "    sentiment = predict_sentiment(coin['name'])\n",
        "    if sentiment['sentiment'] != \"negative\":\n",
        "      resulting_list.append(coin['name'])\n",
        "      if len(resulting_list) >= n:\n",
        "        break\n",
        "  missing = n - len(resulting_list)\n",
        "  for _ in range(missing):\n",
        "    resulting_list.append(\"USDC\")\n",
        "  return resulting_list"
      ],
      "metadata": {
        "id": "kMU3ilf-odfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_picks = get_final_picks(ranked_markets)"
      ],
      "metadata": {
        "id": "Ns9NSHassjyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def adjust_order_size(coin: str, proposed_size: float, info) -> float:\n",
        "    \"\"\"\n",
        "    Retrieves the minimum order increment for the given coin from metadata,\n",
        "    then rounds the proposed_size down to the nearest multiple of that increment.\n",
        "\n",
        "    Returns the adjusted order size.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        meta = info.meta()\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error retrieving metadata: {e}\")\n",
        "        return proposed_size\n",
        "    universe = meta.get(\"universe\", [])\n",
        "    for asset in universe:\n",
        "        if asset.get(\"name\", \"\").upper() == coin.upper():\n",
        "            sz_decimals = asset.get(\"szDecimals\", 8)\n",
        "            min_increment = 1 / (10 ** sz_decimals)\n",
        "            # Floor the proposed size to a multiple of min_increment.\n",
        "            adjusted_size = floor(proposed_size / min_increment) * min_increment\n",
        "            logging.debug(f\"For {coin}: proposed_size={proposed_size} min_increment={min_increment:.8f} adjusted_size={adjusted_size}\")\n",
        "            return adjusted_size\n",
        "    logging.error(f\"Coin {coin} not found in metadata. Using proposed size {proposed_size}.\")\n",
        "    return proposed_size\n",
        "\n",
        "def sell_all_to_usdc(exchange, info):\n",
        "    \"\"\"\n",
        "    Closes all open positions for every asset held by the account.\n",
        "    For each unique coin in info.user_state(), it calls exchange.market_close(coin)\n",
        "    to liquidate the position.\n",
        "    \"\"\"\n",
        "    address = exchange.wallet.address\n",
        "    state = info.user_state(address)\n",
        "    positions = state.get(\"assetPositions\", [])\n",
        "    if not positions:\n",
        "        logging.info(\"No positions to close.\")\n",
        "        return\n",
        "\n",
        "    # Build a set of unique coins with positions.\n",
        "    coins = set()\n",
        "    for pos in positions:\n",
        "        coin = pos.get(\"position\", {}).get(\"coin\")\n",
        "        if coin:\n",
        "            coins.add(coin)\n",
        "\n",
        "    for coin in coins:\n",
        "        logging.info(f\"Attempting to market close all positions for {coin}.\")\n",
        "        order_result = exchange.market_close(coin)\n",
        "        if order_result and order_result.get(\"status\") == \"ok\":\n",
        "            for status in order_result[\"response\"][\"data\"][\"statuses\"]:\n",
        "                try:\n",
        "                    filled = status[\"filled\"]\n",
        "                    logging.info(f\"Market close order #{filled['oid']} for {coin} filled {filled['totalSz']} @{filled['avgPx']}\")\n",
        "                except KeyError:\n",
        "                    logging.error(f\"Error closing position for {coin}: {status.get('error')}\")\n",
        "        else:\n",
        "            logging.error(f\"Market close failed for {coin}: {order_result}\")\n",
        "        time.sleep(2)  # small pause between orders\n",
        "\n",
        "def rebalance_equal_weight(exchange, info, final_picks, slippage=0.01):\n",
        "    \"\"\"\n",
        "    Transforms your current portfolio into the target equal‑weighted portfolio (final_picks)\n",
        "    using the minimum number of trades.\n",
        "\n",
        "    Steps:\n",
        "      1. Retrieve current portfolio state (USDC balance and positions).\n",
        "      2. Compute total portfolio value = USDC balance + sum(value of each position at current mid prices).\n",
        "      3. For each coin in final_picks (which may include duplicates), compute the desired allocation.\n",
        "         Desired allocation for each coin = frequency_in_final_picks * (total_value / total_slots)\n",
        "      4. For each coin currently held but not desired, sell the entire holding.\n",
        "      5. For each coin in the desired portfolio, compute the net difference (desired_value – current_value)\n",
        "         and place a single trade to buy (if under‑allocated) or sell (if over‑allocated). Order size is computed\n",
        "         as (difference in USDC) / (mid price) and then adjusted to the coin’s minimum increment.\n",
        "      6. Any leftover USDC (from rounding) remains uninvested.\n",
        "    \"\"\"\n",
        "    address = exchange.wallet.address\n",
        "    state = info.user_state(address)\n",
        "\n",
        "    # 1. Get current USDC balance.\n",
        "    cross_margin = state.get(\"crossMarginSummary\", {})\n",
        "    try:\n",
        "        usdc_balance = float(cross_margin.get(\"accountValue\", 0))\n",
        "    except Exception as e:\n",
        "        raise ValueError(\"Error parsing USDC balance: \" + str(e))\n",
        "\n",
        "    # 2. Get current positions and compute their value using current mid prices.\n",
        "    positions = state.get(\"assetPositions\", [])\n",
        "    mids = info.all_mids()\n",
        "    current_holdings = {}  # coin -> value in USDC\n",
        "    for pos in positions:\n",
        "        coin = pos.get(\"position\", {}).get(\"coin\")\n",
        "        if not coin:\n",
        "            continue\n",
        "        try:\n",
        "            size = float(pos.get(\"position\", {}).get(\"szi\", 0))\n",
        "            coin_mid = float(mids.get(coin, 0))\n",
        "            value = size * coin_mid\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error processing position for {coin}: {e}\")\n",
        "            continue\n",
        "        current_holdings[coin] = current_holdings.get(coin, 0) + value\n",
        "\n",
        "    total_value = usdc_balance + sum(current_holdings.values())\n",
        "    logging.info(f\"Total portfolio value: {total_value:.2f} USDC (USDC balance: {usdc_balance:.2f}, positions: {current_holdings})\")\n",
        "\n",
        "    # 3. Determine desired allocation from final_picks.\n",
        "    total_slots = len(final_picks)\n",
        "    if total_slots == 0:\n",
        "        logging.info(\"No target picks provided.\")\n",
        "        return\n",
        "    allocation_per_slot = total_value / total_slots\n",
        "    desired_allocation = {}  # coin -> desired USDC value\n",
        "    for coin in final_picks:\n",
        "        desired_allocation[coin] = desired_allocation.get(coin, 0) + allocation_per_slot\n",
        "    logging.info(f\"Desired allocation (USDC): {desired_allocation}\")\n",
        "\n",
        "    # 4. For coins held but not desired, sell entire position.\n",
        "    for coin, value in current_holdings.items():\n",
        "        if coin not in desired_allocation:\n",
        "            logging.info(f\"Coin {coin} is held but not desired. Initiating sell of full position.\")\n",
        "            order_result = exchange.market_close(coin)\n",
        "            if order_result and order_result.get(\"status\") == \"ok\":\n",
        "                logging.info(f\"Market close for {coin} successful: {order_result}\")\n",
        "            else:\n",
        "                logging.error(f\"Market close failed for {coin}: {order_result}\")\n",
        "            time.sleep(2)\n",
        "\n",
        "    # 5. For each coin desired, compute difference and execute trade if needed.\n",
        "    for coin, desired_value in desired_allocation.items():\n",
        "        current_value = current_holdings.get(coin, 0)\n",
        "        diff = desired_value - current_value  # positive: need to buy; negative: need to sell\n",
        "        if abs(diff) < 1e-6:\n",
        "            logging.info(f\"For {coin}: current value meets desired allocation; no trade needed.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            mid_price = float(mids.get(coin, 0))\n",
        "            if mid_price <= 0:\n",
        "                logging.error(f\"No valid mid price for {coin}; skipping trade.\")\n",
        "                continue\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error retrieving mid price for {coin}: {e}\")\n",
        "            continue\n",
        "\n",
        "        order_size = abs(diff) / mid_price  # raw size required\n",
        "        adjusted_size = adjust_order_size(coin, order_size, info)\n",
        "        if adjusted_size <= 0:\n",
        "            logging.error(f\"Adjusted order size for {coin} is zero; skipping trade.\")\n",
        "            continue\n",
        "\n",
        "        if diff > 0:\n",
        "            action = \"buy\"\n",
        "            logging.info(f\"Need to BUY {coin}: additional value {diff:.2f} USDC, raw size {order_size:.8f}, adjusted size {adjusted_size:.8f}\")\n",
        "            order_result = exchange.market_open(coin, True, adjusted_size, None, slippage)\n",
        "        else:\n",
        "            action = \"sell\"\n",
        "            logging.info(f\"Need to SELL {coin}: excess value {abs(diff):.2f} USDC, raw size {order_size:.8f}, adjusted size {adjusted_size:.8f}\")\n",
        "            # For selling partial positions, use a lower-level order with reduce_only set to True.\n",
        "            order_result = exchange.order(\n",
        "                name=coin,\n",
        "                is_buy=False,\n",
        "                sz=adjusted_size,\n",
        "                limit_px=mid_price,\n",
        "                order_type={\"limit\": {\"tif\": \"Ioc\"}},\n",
        "                reduce_only=True\n",
        "            )\n",
        "        if order_result and order_result.get(\"status\") == \"ok\":\n",
        "            logging.info(f\"{action.upper()} order for {coin} executed successfully: {order_result}\")\n",
        "        else:\n",
        "            logging.error(f\"{action.upper()} order for {coin} failed: {order_result}\")\n",
        "        time.sleep(2)\n",
        "\n",
        "    # 6. Log final state.\n",
        "    final_state = info.user_state(address)\n",
        "    logging.info(f\"Rebalance complete. Final state for {address}: {final_state}\")\n",
        "\n",
        "def get_portfolio_positions(exchange, info):\n",
        "    \"\"\"\n",
        "    Retrieves portfolio positions for the current wallet on Hyperliquid.\n",
        "    Returns a list of dictionaries with key details for each position.\n",
        "    \"\"\"\n",
        "    address = exchange.wallet.address\n",
        "    state = info.user_state(address)\n",
        "    logging.info(f\"User state for {address}: {state}\")\n",
        "    positions = state.get(\"assetPositions\", [])\n",
        "\n",
        "    formatted_positions = []\n",
        "    for pos in positions:\n",
        "        position_data = pos.get(\"position\", {})\n",
        "        formatted_positions.append({\n",
        "            \"coin\": position_data.get(\"coin\"),\n",
        "            \"entry_price\": position_data.get(\"entryPx\"),\n",
        "            \"leverage\": position_data.get(\"leverage\"),\n",
        "            \"liquidation_price\": position_data.get(\"liquidationPx\"),\n",
        "            \"margin_used\": position_data.get(\"marginUsed\"),\n",
        "            \"position_value\": position_data.get(\"positionValue\"),\n",
        "            \"return_on_equity\": position_data.get(\"returnOnEquity\"),\n",
        "            \"size\": position_data.get(\"szi\"),\n",
        "            \"unrealized_pnl\": position_data.get(\"unrealizedPnl\")\n",
        "        })\n",
        "\n",
        "    return formatted_positions"
      ],
      "metadata": {
        "id": "VzbKtAA_s00P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rebalance_equal_weight(exchange, info, final_picks)"
      ],
      "metadata": {
        "id": "eEDViDCXr53s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_portfolio_positions(exchange, info)"
      ],
      "metadata": {
        "id": "IWft99gztLFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "info.user_state(address)"
      ],
      "metadata": {
        "id": "1UW5_kFotNGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b25ib_UstpxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}